{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FatimaEzzedinee/ML-bachelor-course-labs-sp24/blob/main/08_Forecasting.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7_JbbGbKA-0s"
      },
      "source": [
        "# Machine Learning SP 2023/2024\n",
        "\n",
        "- Prof. Cesare Alippi\n",
        "- Alvise Dei Rossi ([`alvise.dei.rossi@usi.ch`](mailto:alvise.dei.rossi@usi.ch))<br>\n",
        "- Fatima Ezzeddine ([`fatima.ezzeddine@usi.ch`](mailto:fatima.ezzeddine@usi.ch))<br>\n",
        "- Alessandro Manenti ([`alessandro.manenti@usi.ch`](mailto:alessandro.manenti@usi.ch))\n",
        "\n",
        "---\n",
        "# Lab 08: Forecasting\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vOKpKrBLq79U"
      },
      "source": [
        "## Forecasting sunspots\n",
        "\n",
        "![](https://upload.wikimedia.org/wikipedia/commons/4/47/Solar_Archipelago_-_Flickr_-_NASA_Goddard_Photo_and_Video.jpg)\n",
        "\n",
        "As a case study we will cosider the problem of forecasting the number of **sunspots** using a dataset collected by the solar physics research department of the Royal Observatory of Belgium ([link](http://sidc.oma.be/)).\n",
        "\n",
        "According to Wikipedia:\n",
        "\n",
        "> Sunspots are temporary phenomena on the Sun's photosphere that appear as spots darker than the surrounding areas. They are regions of reduced surface temperature caused by concentrations of magnetic field flux that inhibit convection. Sunspots usually appear in pairs of opposite magnetic polarity. Their number varies according to the approximately 11-year solar cycle.\n",
        "\n",
        "The datset is available on Kaggle ([link](https://www.kaggle.com/robervalt/sunspots)) and frequently updated.\n",
        "\n",
        "For semplicity (and reproducibility), we loaded a snapshot of the dataset in the repo of the course.\n",
        "\n",
        "We start by installing the last version of statsmodels."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ePdaVOZ7HvWq"
      },
      "outputs": [],
      "source": [
        "%pip install statsmodels -U"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jqepj7EelDdS"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "url = \"https://raw.githubusercontent.com/FatimaEzzedinee/ML-bachelor-course-labs-sp24/main/sunspots.csv\"\n",
        "\n",
        "df = pd.read_csv(url,\n",
        "                 parse_dates=True,\n",
        "                 index_col='Date',\n",
        "                 usecols=['Date', 'Monthly Mean Total Sunspot Number'])\n",
        "df = df.rename(columns={'Monthly Mean Total Sunspot Number':'sunspots'})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xhOOi3KcCA6v"
      },
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "__Note__: the time series we're considering since $d=1$ is said to be _univariate_."
      ],
      "metadata": {
        "id": "OMkbfkHONDC-"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "77JPRz5j5v5d"
      },
      "source": [
        "Let's have a look at the data!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4HtmxuqnwgAc"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(20,5))\n",
        "plt.plot(df.index, df['sunspots'])\n",
        "plt.xlabel('year')\n",
        "plt.ylabel('n. sunspots')\n",
        "plt.grid(alpha=0.25)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Gpm5wdb51dR"
      },
      "source": [
        "First of all let's split our data for model evaluation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N_i8YqCu51Oc"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Prepare the data\n",
        "train_df, test_df = train_test_split(df, test_size=0.2, shuffle=True)\n",
        "\n",
        "# scale the data\n",
        "mean = train_df.values.mean()\n",
        "std = train_df.values.std()\n",
        "\n",
        "scale = lambda x : (x - mean) / std\n",
        "inv_scale = lambda x : x * std + mean\n",
        "\n",
        "train_df = scale(train_df)\n",
        "test_df = scale(test_df)\n",
        "\n",
        "# Note that you could do this completely in sklearn with:\n",
        "# from sklearn.preprocessing import StandardScaler\n",
        "#scaler = StandardScaler()\n",
        "# X_train = scaler.fit_transform(train_df)\n",
        "# X_test = scaler.transform(test_df)\n",
        "\n",
        "# THERE IS AN ERROR BEFORE, CAN YOU SPOT IT?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZTc5gubv2kEc"
      },
      "source": [
        "## A simple baseline\n",
        "\n",
        "Simply use the value at the previous time-step to predict the next one:\n",
        "$$\\hat{y}_{t+1} = x_t$$\n",
        "This is usually called a Na√Øve method."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iWMByMb-2r4h"
      },
      "outputs": [],
      "source": [
        "actuals = inv_scale(test_df.values.ravel())\n",
        "\n",
        "mse = np.square(actuals[:-1] - actuals[1:]).mean()\n",
        "print(f\"BASELINE MSE: {mse}\")\n",
        "mae = np.abs(actuals[:-1] - actuals[1:]).mean()\n",
        "print(f\"BASELINE MAE: {mae}\")\n",
        "\n",
        "fig, ax1 = plt.subplots(figsize=(20, 5))\n",
        "ax1.plot(actuals[1:], label='actual')\n",
        "ax1.plot(actuals[:-1], label='pred')\n",
        "ax1.set_ylabel('n. sunspots',fontsize=14)\n",
        "ax1.set_xlabel('idx',fontsize=14)\n",
        "ax1.set_ylim([0,300])\n",
        "plt.legend(loc=\"upper right\")\n",
        "plt.grid(alpha=0.25)\n",
        "ax2 = ax1.twinx()\n",
        "ax2.set_ylabel('residual', color=\"darkgreen\", fontsize=14)\n",
        "ax2.plot(actuals[1:] - actuals[:-1], color=\"darkgreen\", alpha=0.25,label=\"residuals\")\n",
        "ax2.tick_params(axis='y', labelcolor=\"darkgreen\")\n",
        "ax2.set_ylim([-150,150])\n",
        "plt.legend(loc=\"upper left\")\n",
        "fig.tight_layout()\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The fit looks almost perfect, but we should look at the residuals to evaluate the fit. The mismatch between predictions and the actual values can also be seen by zooming in on smaller windows:"
      ],
      "metadata": {
        "id": "y73gy-p5Juht"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib import collections  as mc\n",
        "\n",
        "lines = [[(i, actuals[i-1]), (i, actuals[i])] for i in range(100,125)]\n",
        "lc = mc.LineCollection(lines, linewidths=0.5, linestyle=\"--\", colors=\"darkgreen\")\n",
        "\n",
        "fig, ax1 = plt.subplots(figsize=(10, 5))\n",
        "ax1.plot(range(100,125),actuals[100:125], label='actual')\n",
        "ax1.plot(range(100,125),actuals[99:124], label='pred')\n",
        "ax1.plot([],[],label=\"residuals\",linestyle=\"--\",linewidth=0.5) # fake plot for legend\n",
        "ax1.set_ylabel('n. sunspots',fontsize=12)\n",
        "ax1.set_xlabel('idx',fontsize=12)\n",
        "ax1.add_collection(lc)\n",
        "plt.legend(loc=\"upper left\")\n",
        "plt.grid(alpha=0.25)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ScsJuX0KJ6F0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jnwCSWlr67Us"
      },
      "source": [
        "## Linear models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fkc_AFxk6-Vn"
      },
      "source": [
        "Let's start with ARIMA models. You can find the documentation [here](https://www.statsmodels.org/devel/generated/statsmodels.tsa.arima.model.ARIMA.html).\n",
        "\n",
        "As a reminder. An autoregressive model of order p (AR(p)) model is a linear model which considers for the prediction the past p realizations:\n",
        "\n",
        "$$ \\hat{y}_t = \\phi_1 x_{t-1} + ... + \\phi_p x_{t-p} + c = c + \\sum_{i=1}^p \\phi_i x_{t-i}$$\n",
        "\n",
        "A moving average model of order q (MA(q)) is a linear model which considers for the prediction the past q forecasting errors, i.e. defining the residual as $\\hat{\\eta}_t = y_t - \\hat{y}_t$, a MA(q) model gives predictions:\n",
        "\n",
        "$$\\hat{y}_t = \\theta_1 \\hat{\\eta}_{t-1} + ... + \\theta_q \\hat{\\eta}_{t-q} + c = c + \\sum_{i=1}^q \\theta_i \\hat{\\eta}_{t-i}; \\quad \\quad \\eta_t \\sim WN(0, \\sigma^2)$$\n",
        "\n",
        "Note that this is **NOT** a moving average smoothing.\n",
        "\n",
        "If you include both the autoregressive and moving average components, you get ARMA(p,q) models. To deal with non-stationary time-series, you need to include also differentiation, i.e. $x'(t) = x_t - x_{t-d}$, to get an ARIMA(p, d, q) model.\n",
        "\n",
        "Let's start with an AR(p) model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YDBTC18BSHdl"
      },
      "outputs": [],
      "source": [
        "from statsmodels.tsa.arima.model import ARIMA\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "#order refers to (p,d,q) , often called also (p,i,q)\n",
        "model = ARIMA(train_df, order=(3, 0, 0), trend='n')\n",
        "\n",
        "fit = model.fit()\n",
        "print(fit.summary())\n",
        "\n",
        "# appends test_df to avaiable data\n",
        "fit = fit.append(test_df, refit=False)\n",
        "\n",
        "actuals = test_df.values.ravel()\n",
        "preds = fit.predict(start=len(train_df)).values.ravel()\n",
        "\n",
        "mse = np.square(inv_scale(preds) - inv_scale(actuals)).mean()\n",
        "print(f\"\\n\\nTEST MSE: {mse}\")\n",
        "mae = np.abs(inv_scale(preds) - inv_scale(actuals)).mean()\n",
        "print(f\"TEST MAE: {mae}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's try with a MA(q) model:"
      ],
      "metadata": {
        "id": "Ffy5jXo4YKoz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from statsmodels.tsa.arima.model import ARIMA\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "#ARIMA(p,i,q)\n",
        "model = ARIMA(train_df, order=(0, 0, 2), trend='n')\n",
        "\n",
        "fit = model.fit()\n",
        "print(fit.summary())\n",
        "\n",
        "# appends test_df to avaiable data\n",
        "fit = fit.append(test_df, refit=False)\n",
        "\n",
        "actuals = test_df.values.ravel()\n",
        "preds = fit.predict(start=len(train_df)).values.ravel()\n",
        "\n",
        "mse = np.square(inv_scale(preds) - inv_scale(actuals)).mean()\n",
        "print(f\"\\n\\nTEST MSE: {mse}\")\n",
        "mae = np.abs(inv_scale(preds) - inv_scale(actuals)).mean()\n",
        "print(f\"TEST MAE: {mae}\")"
      ],
      "metadata": {
        "id": "9GJRPVJ7YJql"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "That was quite bad... what about combining them?"
      ],
      "metadata": {
        "id": "ODraeKdxYcYI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#ARIMA(p,i,q)\n",
        "model = ARIMA(train_df, order=(3, 0, 2), trend='n')\n",
        "\n",
        "fit = model.fit()\n",
        "print(fit.summary())\n",
        "\n",
        "# appends test_df to avaiable data\n",
        "fit = fit.append(test_df, refit=False)\n",
        "\n",
        "actuals = test_df.values.ravel()\n",
        "preds = fit.predict(start=len(train_df)).values.ravel()\n",
        "\n",
        "mse = np.square(inv_scale(preds) - inv_scale(actuals)).mean()\n",
        "print(f\"\\n\\nTEST MSE: {mse}\")\n",
        "mae = np.abs(inv_scale(preds) - inv_scale(actuals)).mean()\n",
        "print(f\"TEST MAE: {mae}\")"
      ],
      "metadata": {
        "id": "5SJkvvUYYbg5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Much better.. Do we need also the differentiation?"
      ],
      "metadata": {
        "id": "hG4tPsKPYyW8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#ARIMA(p,i,q)\n",
        "model = ARIMA(train_df, order=(3, 1, 2), trend='n')\n",
        "\n",
        "fit = model.fit()\n",
        "print(fit.summary())\n",
        "\n",
        "# appends test_df to avaiable data\n",
        "fit = fit.append(test_df, refit=False)\n",
        "\n",
        "actuals = test_df.values.ravel()\n",
        "preds = fit.predict(start=len(train_df)).values.ravel()\n",
        "\n",
        "mse = np.square(inv_scale(preds) - inv_scale(actuals)).mean()\n",
        "print(f\"\\n\\nTEST MSE: {mse}\")\n",
        "mae = np.abs(inv_scale(preds) - inv_scale(actuals)).mean()\n",
        "print(f\"TEST MAE: {mae}\")"
      ],
      "metadata": {
        "id": "DU7VebrDYw_T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Seems to obtain about the same results (slightly worse), let's see its predictions:"
      ],
      "metadata": {
        "id": "ZIBBLDPZZAG-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ELKxpf-JCZaB"
      },
      "outputs": [],
      "source": [
        "preds = fit.predict(start=len(train_df), dynamic=False)\n",
        "\n",
        "fig, ax1 = plt.subplots(figsize=(20, 5))\n",
        "ax1.plot(inv_scale(test_df), label='actual')\n",
        "ax1.plot(inv_scale(preds), label='pred')\n",
        "ax1.set_ylabel('n. sunspots',fontsize=14)\n",
        "ax1.set_xlabel('year',fontsize=14)\n",
        "ax1.set_ylim([0,300])\n",
        "plt.legend(loc=\"upper right\")\n",
        "plt.grid(alpha=0.25)\n",
        "ax2 = ax1.twinx()\n",
        "ax2.set_ylabel('residual', color=\"darkgreen\", fontsize=14)\n",
        "ax2.plot(inv_scale(actuals) - inv_scale(preds), color=\"darkgreen\", alpha=0.25,label=\"residuals\")\n",
        "ax2.tick_params(axis='y', labelcolor=\"darkgreen\")\n",
        "ax2.set_ylim([-150,150])\n",
        "plt.legend(loc=\"upper left\")\n",
        "fig.tight_layout()\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "start_idx = 100\n",
        "end_idx = 125\n",
        "\n",
        "fig, ax1 = plt.subplots(figsize=(10, 5))\n",
        "ax1.plot(test_df.index[start_idx:end_idx],inv_scale(test_df)[start_idx:end_idx], label='actual')\n",
        "ax1.plot(test_df.index[start_idx:end_idx],inv_scale(test_df)[start_idx-1:end_idx-1], label='pred naive')\n",
        "ax1.plot(inv_scale(preds)[start_idx:end_idx], label='pred arima')\n",
        "ax1.set_ylabel('n. sunspots',fontsize=12)\n",
        "ax1.set_xlabel('time',fontsize=12)\n",
        "plt.legend()\n",
        "plt.grid(alpha=0.25)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "AFJdUwaOVzk0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JU5TEu3FCA6w"
      },
      "source": [
        "for `dynamic` parameter in `predict` method look [here](https://www.statsmodels.org/0.6.1/generated/statsmodels.tsa.arima_model.ARIMA.predict.html#statsmodels.tsa.arima_model.ARIMA.predict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y1wk7XFWFIWB"
      },
      "outputs": [],
      "source": [
        "# one-step prediction\n",
        "y_pred = fit.predict(start=len(train_df), dynamic=False) #dynamic\n",
        "\n",
        "# recursive prediction\n",
        "n_last = 300\n",
        "y_new = fit.predict(start=len(train_df) + len(test_df) - n_last, dynamic=True)\n",
        "\n",
        "plt.figure(figsize=(12, 5))\n",
        "plt.plot(inv_scale(test_df), label=\"actual\")\n",
        "plt.plot(inv_scale(y_pred), label=\"pred\")\n",
        "plt.plot(inv_scale(y_new), label=\"new\")\n",
        "plt.xlabel('year')\n",
        "plt.ylabel('n. sunspots')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Some final remarks on ARIMA(p,i,q) models:\n",
        "\n",
        "\n",
        "\n",
        "1.   In the end, how do I choose p, i, q?\n",
        "We can try to check goodness of fit based on metrics like AIC, BIC with several tests. Or you can use [auto.arima](https://github.com/alkaline-ml/pmdarima) packages.\n",
        "2.   Can we do more? Yes!\n",
        "*   we can take seasonality into account (SARIMA)\n",
        "*   we can add exogenous variables (e.g., date, time of the year, some other useful predictor, ...) (ARIMAX)\n",
        "*   we can combine the two (SARIMAX)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "_RdsA9fcTbm8"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XzmLzbLnklWv"
      },
      "source": [
        "## Nonlinear Autoregressive models"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "From the theory:\n",
        "\n",
        "$$ \\hat{y}_t = f_\\Theta (x_{t-1} + ... + x_{t-p})$$\n",
        "\n",
        "with $y_t = x_t$ and $f_\\Theta$ a nonlinear function."
      ],
      "metadata": {
        "id": "gaIs9MM1bxH4"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wFNM5ofZ5QNQ"
      },
      "source": [
        "### Let's divide data into windows\n",
        "\n",
        "```\n",
        "            historical data                   | future observations\n",
        "--------------------------------------------------------------------\n",
        "x(1) x(2) ... x(t-p) x(t-p+1) ... x(t-1) x(t) | x(t+1)  x(t+2) ...\n",
        "                    \\________________________/| \\____/\n",
        "                       time window            | value to\n",
        "                                              | be predicted\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c7CmFQr1rzEg"
      },
      "outputs": [],
      "source": [
        "# Time windows\n",
        "def get_time_windows(sequence, window_size):\n",
        "    time = np.arange(sequence.shape[0])\n",
        "    xseq = []\n",
        "    yseq = []\n",
        "    for t in time[:-window_size]:\n",
        "        xseq.append(sequence[t:t+window_size])\n",
        "        yseq.append(sequence[t+window_size]) # one-step prediction\n",
        "    xseq = np.array(xseq)\n",
        "    yseq = np.array(yseq)\n",
        "    #train-test split\n",
        "    return xseq, yseq.ravel()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MBK7me3t0xWi"
      },
      "outputs": [],
      "source": [
        "# Prepare the data\n",
        "p = 24\n",
        "\n",
        "x_train, y_train = get_time_windows(sequence=train_df.values.ravel(), window_size=p)\n",
        "x_test, y_test = get_time_windows(sequence=test_df.values.ravel(), window_size=p)\n",
        "print(\"training data\", x_train.shape, y_train.shape)\n",
        "print(\"test data\", x_test.shape, y_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y3MzRgXqKW2a"
      },
      "source": [
        "We can use the usual syntax to build a neural network with pytorch and train it to predict the next value in the time-series.\n",
        "\n",
        "We can formulate it as a regression problem."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)\n",
        "\n",
        "class FFNN(nn.Module):\n",
        "    def __init__(self, win_size):\n",
        "        super(FFNN, self).__init__()\n",
        "        self.fc1 = nn.Linear(win_size, 64)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(64, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "oOkjcBQgdNoy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = FFNN(p).to(device)\n",
        "criterion = nn.L1Loss()\n",
        "optimizer = optim.Adam(model.parameters(),lr=0.001)\n",
        "\n",
        "BATCH_SIZE = 16\n",
        "n_epochs = 50"
      ],
      "metadata": {
        "id": "rRXIqb28ftwy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainset = torch.utils.data.TensorDataset(torch.tensor(x_train, dtype=torch.float32),\n",
        "                                          torch.tensor(y_train, dtype=torch.float32))\n",
        "testset = torch.utils.data.TensorDataset(torch.tensor(x_test, dtype=torch.float32),\n",
        "                                         torch.tensor(y_test, dtype=torch.float32))\n",
        "\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=BATCH_SIZE,\n",
        "                                          shuffle=False, num_workers=2)\n",
        "\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=BATCH_SIZE,\n",
        "                                         shuffle=False, num_workers=2)"
      ],
      "metadata": {
        "id": "MwFD18g6fURl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, criterion, optimizer, train_loader, n_epochs, device):\n",
        "    training_losses = []\n",
        "    validation_losses = []\n",
        "\n",
        "    train_length = len(trainloader)\n",
        "    for epoch in range(n_epochs):\n",
        "        model.train()\n",
        "        train_loss = 0.\n",
        "\n",
        "        for x, y in train_loader:           # Access the training data\n",
        "            optimizer.zero_grad()           # Zero the gradients\n",
        "            x, y = x.to(device), y.to(device)\n",
        "            y_pred = model(x)               # Forward passs\n",
        "\n",
        "            loss = criterion(y_pred, y)\n",
        "            loss.backward()                 # Compute the gradients\n",
        "            optimizer.step()                # Update the weights\n",
        "\n",
        "            train_loss += loss.item()\n",
        "        training_losses.append(train_loss/train_length) # Save the loss for plotting\n",
        "\n",
        "    return training_losses"
      ],
      "metadata": {
        "id": "KLAsidFzdSX6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_losses = train(model, criterion, optimizer, trainloader, n_epochs, device)\n",
        "plt.plot(training_losses)\n",
        "plt.grid(alpha=0.5)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "KulZXeOKghEg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = []\n",
        "actual = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for x, y in testloader:\n",
        "        x, y = x.to(device), y.to(device)\n",
        "        y_pred = model(x)\n",
        "        for i in range(len(y_pred)):\n",
        "          predictions.append(y_pred[i].item())\n",
        "          actual.append(y[i].item())\n",
        "\n",
        "preds = np.array(predictions)\n",
        "actual = np.array(actual)\n",
        "\n",
        "mse = np.square(inv_scale(preds) - inv_scale(actual)).mean()\n",
        "print(f\"TEST MSE: {mse}\")\n",
        "mae = np.abs(inv_scale(preds) - inv_scale(actual)).mean()\n",
        "print(f\"TEST MAE: {mae}\")"
      ],
      "metadata": {
        "id": "C6H3KICLjkus"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kEFtODpIuXor"
      },
      "outputs": [],
      "source": [
        "y_pred = model(torch.tensor(x_test, dtype=torch.float32, device=device)).cpu().detach().numpy()\n",
        "\n",
        "plt.figure(figsize=(12, 5))\n",
        "plt.plot(np.arange(y_test.shape[0]), inv_scale(y_test), label=\"actual\")\n",
        "plt.plot(np.arange(y_test.shape[0]), inv_scale(y_pred), label=\"pred\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n499rYGT61rm"
      },
      "source": [
        "It looks like that the NAR model is not very good."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QFRE6_e5HB5P"
      },
      "source": [
        "## Recurrent neural networks\n",
        "\n",
        "Finally let's try out a more advanced architecture: SimpleRNN networks. Documentation [here](https://keras.io/api/layers/recurrent_layers/simple_rnn/)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleRNNModel(nn.Module):\n",
        "    def __init__(self, win_size):\n",
        "        super(SimpleRNNModel, self).__init__()\n",
        "        self.reshape = nn.Linear(win_size, win_size)\n",
        "        self.rnn = nn.RNN(input_size=1, hidden_size=16, batch_first=True)\n",
        "        self.fc = nn.Linear(16, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(x.size(0), -1, 1)\n",
        "        x, _ = self.rnn(x)\n",
        "        x = x[:, -1, :]\n",
        "        x = self.fc(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "-kXPB3sIsX9F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = SimpleRNNModel(p).to(device)\n",
        "criterion = nn.L1Loss()\n",
        "optimizer = optim.Adam(model.parameters(),lr=0.001)\n",
        "\n",
        "BATCH_SIZE = 16\n",
        "n_epochs = 50"
      ],
      "metadata": {
        "id": "gEoblh2vsj0h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_losses = train(model, criterion, optimizer, trainloader, n_epochs, device)\n",
        "plt.plot(training_losses)\n",
        "plt.grid(alpha=0.5)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Y1uawvXKs6VO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = []\n",
        "actual = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for x, y in testloader:\n",
        "        x, y = x.to(device), y.to(device)\n",
        "        y_pred = model(x)\n",
        "        for i in range(len(y_pred)):\n",
        "          predictions.append(y_pred[i].item())\n",
        "          actual.append(y[i].item())\n",
        "\n",
        "preds = np.array(predictions)\n",
        "actual = np.array(actual)\n",
        "\n",
        "mse = np.square(inv_scale(preds) - inv_scale(actual)).mean()\n",
        "print(f\"TEST MSE: {mse}\")\n",
        "mae = np.abs(inv_scale(preds) - inv_scale(actual)).mean()\n",
        "print(f\"TEST MAE: {mae}\")"
      ],
      "metadata": {
        "id": "aJmOeM-OtGRs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model(torch.tensor(x_test, dtype=torch.float32, device=device)).cpu().detach().numpy()\n",
        "\n",
        "plt.figure(figsize=(12, 5))\n",
        "plt.plot(np.arange(y_test.shape[0]), inv_scale(y_test), label=\"actual\")\n",
        "plt.plot(np.arange(y_test.shape[0]), inv_scale(y_pred), label=\"pred\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "0iC6IxzztM_U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LSTMModel(nn.Module):\n",
        "    def __init__(self, win_size):\n",
        "        super(LSTMModel, self).__init__()\n",
        "        self.reshape = nn.Linear(win_size, win_size)\n",
        "        self.lstm = nn.LSTM(input_size=1, hidden_size=16, batch_first=True)\n",
        "        self.fc = nn.Linear(16, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(x.size(0), -1, 1)\n",
        "        x, (hn, cn) = self.lstm(x)\n",
        "        x = x[:, -1, :]\n",
        "        x = self.fc(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "KH-T1RKXtjsy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare the data\n",
        "p = 150\n",
        "\n",
        "x_train, y_train = get_time_windows(sequence=train_df.values.ravel(), window_size=p)\n",
        "x_test, y_test = get_time_windows(sequence=test_df.values.ravel(), window_size=p)\n",
        "print(\"training data\", x_train.shape, y_train.shape)\n",
        "print(\"test data\", x_test.shape, y_test.shape)\n",
        "\n",
        "trainset = torch.utils.data.TensorDataset(torch.tensor(x_train, dtype=torch.float32),\n",
        "                                          torch.tensor(y_train, dtype=torch.float32))\n",
        "testset = torch.utils.data.TensorDataset(torch.tensor(x_test, dtype=torch.float32),\n",
        "                                         torch.tensor(y_test, dtype=torch.float32))\n",
        "\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=BATCH_SIZE,\n",
        "                                          shuffle=False, num_workers=2)\n",
        "\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=BATCH_SIZE,\n",
        "                                         shuffle=False, num_workers=2)"
      ],
      "metadata": {
        "id": "KZQpabYnzX8u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = LSTMModel(p).to(device)\n",
        "criterion = nn.L1Loss()\n",
        "optimizer = optim.Adam(model.parameters(),lr=0.001)\n",
        "\n",
        "BATCH_SIZE = 16\n",
        "n_epochs = 25"
      ],
      "metadata": {
        "id": "SqpeQ5vtt-mA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_losses = train(model, criterion, optimizer, trainloader, n_epochs, device)\n",
        "\n",
        "plt.plot(training_losses)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "OF_DdHznuBfH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = []\n",
        "actual = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for x, y in testloader:\n",
        "        x, y = x.to(device), y.to(device)\n",
        "        y_pred = model(x)\n",
        "        for i in range(len(y_pred)):\n",
        "          predictions.append(y_pred[i].item())\n",
        "          actual.append(y[i].item())\n",
        "\n",
        "preds = np.array(predictions)\n",
        "actual = np.array(actual)\n",
        "\n",
        "mse = np.square(inv_scale(preds) - inv_scale(actual)).mean()\n",
        "print(f\"TEST MSE: {mse}\")\n",
        "mae = np.abs(inv_scale(preds) - inv_scale(actual)).mean()\n",
        "print(f\"TEST MAE: {mae}\")"
      ],
      "metadata": {
        "id": "dET-j3HvuKpY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model(torch.tensor(x_test, dtype=torch.float32, device=device)).cpu().detach().numpy()\n",
        "\n",
        "plt.figure(figsize=(12, 5))\n",
        "plt.plot(np.arange(y_test.shape[0]), inv_scale(y_test), label=\"actual\")\n",
        "plt.plot(np.arange(y_test.shape[0]), inv_scale(y_pred), label=\"pred\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "3B3-1GGuuUVl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s9mqVmE1LBjl"
      },
      "source": [
        "As you can see it's not always trivial to beat linear autoregressive models.\n",
        "\n",
        "However... many more things left to explore with non-linear models:\n",
        "\n",
        "* __Tune hyperparameters!__\n",
        "* Stack multiple recurrent layers;\n",
        "* try 1D-CNNs;\n",
        "* try [GRUs](https://pytorch.org/docs/stable/generated/torch.nn.GRU.html);\n",
        "* try [Seq2Seq](https://github.com/bentrevett/pytorch-seq2seq) models;\n",
        "* try [more advanced transformer models](https://huggingface.co/docs/transformers/model_doc/time_series_transformer)\n",
        "* multi-step predictions;\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Want to learn more about forecasting? [This](https://otexts.com/fpp3/) is a good resource to start.\n",
        "\n",
        "Also take a look at [prophet](https://facebook.github.io/prophet/)."
      ],
      "metadata": {
        "id": "kRGRt4WZFQfL"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}