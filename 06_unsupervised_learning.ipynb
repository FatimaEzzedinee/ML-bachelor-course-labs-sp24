{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FatimaEzzedinee/ML-bachelor-course-labs-sp24/blob/main/07_unsupervised_learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xK6oJGO3smnq"
      },
      "source": [
        "# Machine Learning SP 2023/2024\n",
        "\n",
        "- Prof. Cesare Alippi\n",
        "- Alvise Dei Rossi ([`alvise.dei.rossi@usi.ch`](mailto:alvise.dei.rossi@usi.ch))<br>\n",
        "- Fatima Ezzeddine ([`fatima.ezzeddine@usi.ch`](mailto:fatima.ezzeddine@usi.ch))<br>\n",
        "- Alessandro Manenti ([`alessandro.manenti@usi.ch`](mailto:alessandro.manenti@usi.ch))\n",
        "\n",
        "---\n",
        "# Lab 07: Unsupervised learning\n",
        "\n",
        "In this lab, we will see practical applications of unsupervised learning techniques.\n",
        "\n",
        "We will focus on two main tasks:\n",
        "\n",
        "1. Clustering: the goal is to group together similar instances togheter into _clusters_. It's a great tool for several ML tasks like data analysis, semi-supervised learning, and more.\n",
        "2. Dimensionality reduction: reducing the number of features considerably, possibly turning an intractable problem into a tractable one. Furthermore, it can be incredibly useful for visualization purposes for high dimensional data.\n",
        "\n",
        "We will use two very famous/common datasets to illustrate the main concepts and apply these methods using sklearn implementations:\n",
        " - [Iris](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_iris.html#sklearn.datasets.load_iris)\n",
        " - [Fashion-MNIST](https://github.com/zalandoresearch/fashion-mnist)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fJl2L7sNQ-zX"
      },
      "source": [
        "\n",
        "## 7.1 Clustering the Iris dataset\n",
        "\n",
        "---\n",
        "\n",
        "We've seen this dataset for classification tasks also in the previous lab. However, this time we analyze the Iris dataset by considering **only the features**, without the targets (i.e., the classes). Let's start by loading the dataset and getting a sense of it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hi5yKDwV8Sqn"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import load_iris\n",
        "\n",
        "# The Iris dataset is easily available with sklearn\n",
        "iris = load_iris()\n",
        "\n",
        "# several attributes of the dataset allow for an easy description of it\n",
        "print(list(iris.keys()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yNwmlzDz27Wz"
      },
      "outputs": [],
      "source": [
        "print(iris['DESCR'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M5RucxZp06yS"
      },
      "outputs": [],
      "source": [
        "print('feature_names:\\n', iris['feature_names'])\n",
        "print()\n",
        "print('target_names:\\n', iris['target_names'])\n",
        "print()\n",
        "print('data:\\n', iris['data'][:10]) # let's look for example at the first 10 samples\n",
        "print()\n",
        "print('target:\\n', iris['target']) # notice that the dataset when loaded is ordered by labels (which we're not going to use)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DHj7hStgKPH9"
      },
      "outputs": [],
      "source": [
        "# extract data\n",
        "X = iris.data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z2jzbohUKT2F"
      },
      "source": [
        "**Remark:** This should be an **unsupervised** learning setup. So, even though `iris.target` is present, we assume to have **no label** associated with the data.\n",
        "\n",
        "Now let's see the shapes of the data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oOcsH8-csmMt"
      },
      "outputs": [],
      "source": [
        "print('Shape of X:', X.shape)\n",
        "\n",
        "(n, d) = X.shape\n",
        "print('d:', d)\n",
        "print('n:', n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "95GxDfJb7yUj"
      },
      "source": [
        "### 7.1.1 Data visualization\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iHAavOb7-UlW"
      },
      "source": [
        "#### Histograms\n",
        "\n",
        "Let's see the estimated pdf of each component (i.e., feature) by means of the histograms."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NPXuT8k471qN"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(18, 4))\n",
        "\n",
        "for i in range(d):\n",
        "    # a subplot for each feature\n",
        "    plt.subplot(1, d, i+1)\n",
        "\n",
        "    # histogram\n",
        "    plt.hist(X[:, i], density=True, color=f'C{i}',alpha=0.8)\n",
        "\n",
        "    # axis labels\n",
        "    plt.xlabel('$x_{}$: {}'.format(i, iris.feature_names[i]), fontsize=12)\n",
        "    if i == 0:\n",
        "      plt.ylabel('estimated pdf', fontsize=12)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IkIzyTUHM9Ls"
      },
      "source": [
        "A couple of observations:\n",
        "\n",
        "* the different ranges\n",
        "* $x_2$ and $x_3$ are roughly bimodal, which might indicate the presence of an easy to spot cluster."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RYBLsHDH6sFQ"
      },
      "source": [
        "\n",
        "#### Scatter plots\n",
        "\n",
        "We try to plot more features at the same time. We have 4 features but we can visualize at most 3D.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QHZvlAeD1cAQ"
      },
      "outputs": [],
      "source": [
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "\n",
        "fig = plt.figure(figsize=(15, 6))\n",
        "\n",
        "ax = fig.add_subplot(121, projection='3d')\n",
        "ax.scatter(X[:, 0], X[:, 1], X[:, 2])\n",
        "ax.set_xlabel(f'$x_0$: {iris.feature_names[0]}')\n",
        "ax.set_ylabel(f'$x_1$: {iris.feature_names[1]}')\n",
        "ax.set_zlabel(f'$x_2$: {iris.feature_names[2]}')\n",
        "\n",
        "ax = fig.add_subplot(122, projection='3d')\n",
        "ax.scatter(X[:, 0], X[:, 2], X[:, 3])\n",
        "ax.set_xlabel(f'$x_0$: {iris.feature_names[0]}')\n",
        "ax.set_ylabel(f'$x_2$: {iris.feature_names[2]}')\n",
        "ax.set_zlabel(f'$x_3$: {iris.feature_names[3]}')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lfIOdPHy68sv"
      },
      "source": [
        "It seems that we can identify in a easier way clusters by watching $x_0, x_2$ and $x_3$ jointly instead of $x_0, x_1$ and $x_2$. Can't we?\n",
        "Or maybe it just depends on where we are looking at the data from... Notice that in the next plots we're just changing `elev` and `azim` parameters for the subplots."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3lD2yrpkPKYb"
      },
      "outputs": [],
      "source": [
        "fig = plt.figure(figsize=(15, 6))\n",
        "\n",
        "ax = fig.add_subplot(121, projection='3d', elev=-150, azim=110)\n",
        "ax.scatter(X[:, 0], X[:, 1], X[:, 2])\n",
        "ax.set_xlabel(f'$x_0$: {iris.feature_names[0]}')\n",
        "ax.set_ylabel(f'$x_1$: {iris.feature_names[1]}')\n",
        "ax.set_zlabel(f'$x_2$: {iris.feature_names[2]}')\n",
        "\n",
        "ax = fig.add_subplot(122, projection='3d', elev=-150, azim=110)\n",
        "ax.scatter(X[:, 0], X[:, 2], X[:, 3])\n",
        "ax.set_xlabel(f'$x_0$: {iris.feature_names[0]}')\n",
        "ax.set_ylabel(f'$x_2$: {iris.feature_names[2]}')\n",
        "ax.set_zlabel(f'$x_3$: {iris.feature_names[3]}')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bPjfnHqLPRDo"
      },
      "source": [
        "Without the right perspective we may miss important clues.\n",
        "\n",
        "2D plots are usually less subject to this kind of problems and clearer than 3D ones (personal opinion!). Let's try all possible combinations of pairs of features for the visualization.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TmlNJSjX8cJv"
      },
      "outputs": [],
      "source": [
        "def plot_every_pair(X, colors=None, same_axis=False, label_pfx=\"x\", include_var_names=True):\n",
        "    d = X.shape[1]\n",
        "    if colors is None:\n",
        "        colors = np.zeros(X.shape[0])\n",
        "    n_plots = d*(d-1)//2\n",
        "    plt.figure(figsize=(3 * max(2, n_plots), 8))\n",
        "    ct = 0\n",
        "    for i in range(1, d+1):\n",
        "        for j in range(i+1, d+1):\n",
        "            ct += 1\n",
        "            plt.subplot(2, int(np.ceil(n_plots/2)), ct)\n",
        "            plt.scatter(X[:, i-1], X[:, j-1], c=colors)\n",
        "            plt.xlabel(f\"${label_pfx}_{i-1}$: {iris.feature_names[i-1] if include_var_names else ''}\", fontsize=12)\n",
        "            plt.ylabel(f\"${label_pfx}_{j-1}$: {iris.feature_names[j-1] if include_var_names else ''}\", fontsize=12)\n",
        "            if same_axis:\n",
        "                # Use same axis scaling\n",
        "                plt.xlim([X.min()-1, X.max()+1])\n",
        "                plt.ylim([X.min()-1, X.max()+1])\n",
        "            plt.grid(alpha=0.5)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "plot_every_pair(X)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b2YvOsyVQII6"
      },
      "source": [
        "Be careful about the different ranges!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UBnwPRvkQNEb"
      },
      "outputs": [],
      "source": [
        "plot_every_pair(X, same_axis=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8JpGgWB3QBF4"
      },
      "source": [
        "#### Seaborn\n",
        "\n",
        "A cool package for data visualization is `seaborn`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "edcIRy8fPlak"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "\n",
        "sns.pairplot(pd.DataFrame(X, columns=iris.feature_names)) # notice that the function expects the data to be a Pandas DataFrame\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ozdm9rms-vsQ"
      },
      "source": [
        "On the diagonal the pdf of the single features is shown, while in the other plots every pair of 2D scatter plot is shown. Notice that you can look only at half of it (upper or lower) and you'd get the same information, you can control this with the `corner=True` parameter. Several other visualizations are possible with this function. Check [its documentation](https://seaborn.pydata.org/generated/seaborn.pairplot.html).\n",
        "\n",
        "__Note__ : the visualization above is rather difficult/cumbersome when the number of features is large."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I70KdBun9jmp"
      },
      "source": [
        "### 7.1.2 Principal Component Analysis\n",
        "\n",
        "Several ML problems involve thousands or even milions of features (think for example about some problems in genomics where you might have few samples (e.g., patients' tissue samples), and each one can have thousands of gene expression levels). This is an issue, particularly for some family of models, which is referred to as _the curse of dimensionality_. Furthermore, many curious and counter-intuitive (from our usual 2D or 3D intuitions) things happen in high dimensional spaces: for example, samples will tend to be far away from each other, making predictions and generalization tricky. As [Thomas Banchoff wrote](https://www.quantamagazine.org/a-mathematicians-guided-tour-through-high-dimensions-20210913/):\n",
        "\n",
        "> “All of us are slaves to the prejudices of our own dimension.\"\n",
        "\n",
        "However, there's hope: in most real-world problems, training instances are _not_ spread out uniformly across all dimensions; they tend to lie on a lower dimensional subspace (often referred to as _manifold_). Dimensionality reduction techniques aim to find such subspace. Several exist, but the most used and famous is __PCA__, which we're going to see in depth.\n",
        "\n",
        "Recall the steps from the theory:\n",
        "\n",
        "1. Let $X \\in \\mathbb{R}^{n \\times d}$ be the dataset\n",
        "1. Subtract the mean. Should we rescale?\n",
        "  $$ X \\leftarrow X - \\overline{X} $$\n",
        "1. Consider the sample covariance matrix\n",
        "  $$\\hat{\\Sigma} = \\frac{1}{n-1} X^\\top X$$\n",
        "1. Compute the symmetrical and semidefinite positive\n",
        "  $$H = X^\\top X$$\n",
        "  and its eigen-decomposition\n",
        "  $$ H = U \\Lambda U^\\top $$\n",
        "  where $U \\in \\mathbb{R}^{d \\times d}$ is the eigenvectors matrix and $\\Lambda \\in \\mathbb{R}^{d \\times d}$ is the eigenvalues matrix (diagonal).\n",
        "\n",
        "  **Remark 1:** Eigenvalues and eigenvectors: $H \\mathbf u = \\lambda \\mathbf u$\n",
        "\n",
        "1. Now apply the transformation\n",
        "  1. Lossless: apply $U^\\top \\mathbf x$ to each vector (simple rotation).\n",
        "  2. Lossy:\n",
        "    - Discard $l$ eigenvectors obtaining $\\tilde{U} \\in \\mathbb{R}^{d \\times d-l}$.\n",
        "    - apply transformation $\\tilde U^\\top \\mathbf x$ to each vector.\n",
        "\n",
        "  To transform the entire dataset, simply do $XU$ or $X\\tilde U$.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JDQf58ENAxuv"
      },
      "outputs": [],
      "source": [
        "X_mean = np.mean(X, axis=0, keepdims=True)\n",
        "X0 = X - X_mean\n",
        "\n",
        "H = (X0.T).dot(X0)\n",
        "lam, U = np.linalg.eigh(H)\n",
        "\n",
        "print(\"shapes:\", lam.shape, U.shape)\n",
        "print(\"eigenvalues:\", lam)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RoTyknqWFMVN"
      },
      "source": [
        "We need to reverse `lam` and `U` since we want the eigenvalues to be sorted in descending order."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SB4Ohwt9-YRN"
      },
      "outputs": [],
      "source": [
        "# Sort the eigenvalues\n",
        "lam = lam[::-1]\n",
        "U = U[:, ::-1]\n",
        "\n",
        "plt.plot(lam, 'o-')\n",
        "plt.title(\"eigenvalues\")\n",
        "plt.grid()\n",
        "plt.xlabel(\"component\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we apply the (lossless) transformation and plot the transformed data, notice how the first two principal components preserve the most variance in the data."
      ],
      "metadata": {
        "id": "5ryBf7gr79lG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bVozxQ8FBcD1"
      },
      "outputs": [],
      "source": [
        "# Apply rotation\n",
        "X_rot = X0.dot(U)\n",
        "\n",
        "sns.pairplot(pd.DataFrame(X_rot, columns=[\"$pc_0$\",\"$pc_1$\",\"$pc_2$\",\"$pc_3$\"]), corner=True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We consider only the first two eigenvectors and discard the other two, effectively reduced the number of dimensions from 4 to 2. Notice that we lose some interpretability in doing so. What are the new features now?"
      ],
      "metadata": {
        "id": "dgsS8uwQ8uK5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iRLx6rsl7BlE"
      },
      "outputs": [],
      "source": [
        "# Apply reduced transformation\n",
        "l = 2  # columns to discard\n",
        "Utilde = U[:, :d-l]\n",
        "X_red = X0.dot(Utilde)\n",
        "# Equivalent to X_red = X_rot[:, :d-l]\n",
        "\n",
        "plot_every_pair(X_red, same_axis=True, label_pfx=\"pc\", include_var_names=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LPF8hWfsyxiH"
      },
      "source": [
        "As usual, `sklearn` can speed up our work! Notice that the result is equal."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xSBmDO-a8pSt",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# PCA with sklearn\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# d:    num of original features (= num of all principal components)\n",
        "# l:    num of discarded principal components\n",
        "# d-l:  num of considered principal components\n",
        "pca = PCA(n_components=d-l)\n",
        "pca.fit(X0)\n",
        "X_red = pca.transform(X0)\n",
        "X_red[:, 0] = -X_red[:, 0]  # reverse dimension zero since corresponding eigenvector is symmetric wrt our solution\n",
        "\n",
        "plot_every_pair(X_red, same_axis=True, label_pfx=\"pc\", include_var_names=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CfYSb1UB6RZ-"
      },
      "source": [
        "### 7.1.3 Data reconstruction\n",
        "\n",
        "What about if we want to come back to the original number of components?\n",
        "\n",
        "$$\\mathbf x \\to \\mathbf {\\tilde x} \\to \\mathbf x_{rec} \\approx \\mathbf x$$\n",
        "\n",
        "where $\\mathbf x \\in \\mathbb{R}^{d}, \\mathbf {\\tilde x} \\in \\mathbb{R}^{d-l}$ and $\\mathbf x_{rec} \\in \\mathbb{R}^{d}$. In this way we are able to **compress** the original data in a low dimensional space and restore them (in a **lossy** way!).\n",
        "\n",
        "- Transformation: $\\mathbf{\\tilde x}=\\tilde U^\\top \\mathbf x$.\n",
        "- Reconstruction (inverse transformation): $\\mathbf x_{rec} = \\tilde U \\mathbf{\\tilde x}$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QnA1N7VUyBT_"
      },
      "outputs": [],
      "source": [
        "# Visualize original vs reconstructed dataset\n",
        "fig = plt.figure(figsize=(18, 4))\n",
        "fig.subplots_adjust(wspace=.4)\n",
        "\n",
        "# Original dataset\n",
        "ax = fig.add_subplot(131, projection='3d', elev=30, azim=160)\n",
        "\n",
        "ax.scatter(X0[:, 0], X0[:, 2], X0[:, 3]) #, X[:, 3])\n",
        "ax.set_xlabel('$x_0$')\n",
        "ax.set_ylabel('$x_2$')\n",
        "ax.set_zlabel('$x_3$')\n",
        "ax.set_title(\"$X$\")\n",
        "\n",
        "# Principal components\n",
        "ax = fig.add_subplot(132)\n",
        "ax.scatter(X_red[:, 0], X_red[:, 1])\n",
        "ax.set_xlabel('$pc_0$')\n",
        "ax.set_ylabel('$pc_1$')\n",
        "ax.set_title(\"Principal Components\")\n",
        "ax.axis(\"equal\")\n",
        "\n",
        "# Reconstructed dataset\n",
        "ax = fig.add_subplot(133, projection='3d', elev=30, azim=160)\n",
        "# reconstruct, notice the inverse transformation is taken care directly by sklearn method!\n",
        "X_rec = pca.inverse_transform(X_red)\n",
        "# which is equivalent to\n",
        "# X_red_ = X.dot(Utilde)\n",
        "# X_rec_ = X_red_.dot(Utilde.T)\n",
        "\n",
        "ax.scatter(X_rec[:, 0], X_rec[:, 2], X_rec[:, 3])\n",
        "ax.set_xlabel('$x_0$')\n",
        "ax.set_ylabel('$x_2$')\n",
        "ax.set_zlabel('$x_3$')\n",
        "ax.set_title(\"$X$ reconstructed\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SbwfV_zUJQK7"
      },
      "outputs": [],
      "source": [
        "print(\"Original Data\")\n",
        "sns.pairplot(pd.DataFrame(X, columns=iris.feature_names), corner=True)\n",
        "plt.show()\n",
        "print(\"\\n\\nReduced Data\")\n",
        "sns.pairplot(pd.DataFrame(X_red, columns=[f'$pc_{pc}$' for pc in range(d-l)]), corner=True)\n",
        "plt.show()\n",
        "print(\"\\n\\nReconstructed Data\")\n",
        "sns.pairplot(pd.DataFrame(X_rec, columns=iris.feature_names), corner=True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Indeed we can see a loss of information due to the compression the data have undergone. We can also get a sense in terms of explained variance of _how much_ information we lost in the process:"
      ],
      "metadata": {
        "id": "Qe4JJXwdD7Sx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pca.explained_variance_ratio_"
      ],
      "metadata": {
        "id": "IzM1fIufD1L7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The first two principal components account for more or less 98% of the variance in the original data. Effectively we halved the features, but only lost 2% of the implied variance. We will see in the last part of this lab a clearer example of how much is lost in this process of compression and reconstruction."
      ],
      "metadata": {
        "id": "O0WbwYbtEc5s"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mmvk-zM9Tx6y"
      },
      "source": [
        "### 7.1.4 Clustering: k-means\n",
        "\n",
        "Now that we managed to represent the original dataset in a low dimensional space we can use the $k$-means clustering technique to classify the data into groups. Sklearn, as usual, has a practical [KMeans](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html) class ready to use."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QZSFEHNK6sjc"
      },
      "outputs": [],
      "source": [
        "from sklearn.cluster import KMeans\n",
        "\n",
        "k_clusters = 2\n",
        "\n",
        "k_means = KMeans(n_clusters=k_clusters, n_init=10)\n",
        "cluster_label = k_means.fit_predict(X_red)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GEBoYXMX7bHG"
      },
      "outputs": [],
      "source": [
        "# 3d\n",
        "fig = plt.figure(figsize=(12, 4))\n",
        "ax = fig.add_subplot(121, projection='3d', elev=30, azim=160)\n",
        "ax.scatter(X[:, 0], X[:, 1], X[:, 2], c=cluster_label)\n",
        "ax.set_xlabel('$x_0$')\n",
        "ax.set_ylabel('$x_1$')\n",
        "ax.set_zlabel('$x_2$')\n",
        "# 2d PC\n",
        "ax = fig.add_subplot(122)\n",
        "ax.scatter(X_red[:, 0], X_red[:, 1], c=cluster_label)\n",
        "ax.set_xlabel('$x_0$')\n",
        "ax.set_ylabel('$x_1$')\n",
        "ax.axis(\"equal\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HPbfT-xz7n4A"
      },
      "source": [
        "Since we know that there are three classes in `iris.target`..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nyRzLgYTDEj7"
      },
      "outputs": [],
      "source": [
        "# Plot the real labels\n",
        "# 3d\n",
        "fig = plt.figure(figsize=(12, 4))\n",
        "ax = fig.add_subplot(121, projection='3d', elev=30, azim=160)\n",
        "for c, label in enumerate(iris.target_names):\n",
        "  idxs = iris.target == c\n",
        "  ax.scatter(X[idxs, 0], X[idxs, 1], X[idxs, 2], label=label)\n",
        "ax.set_xlabel('$x_0$')\n",
        "ax.set_ylabel('$x_1$')\n",
        "ax.set_zlabel('$x_2$')\n",
        "\n",
        "# 2d PC\n",
        "ax = fig.add_subplot(122)\n",
        "for c, label in enumerate(iris.target_names):\n",
        "  idxs = iris.target == c\n",
        "  ax.scatter(X_red[idxs, 0], X_red[idxs, 1], label=label)\n",
        "ax.set_xlabel('$x_0$')\n",
        "ax.set_ylabel('$x_1$')\n",
        "ax.axis(\"equal\")\n",
        "ax.legend()\n",
        "ax.set_title(\"Classes (not clusters!)\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Px4OtYmw6UsO"
      },
      "source": [
        "However, k-means (as well as any other clustering method) does not necessarily retrieve the same classes, because classes are not necessarily confined into clusters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nUuGPCB_6TqT"
      },
      "outputs": [],
      "source": [
        "from sklearn.cluster import KMeans\n",
        "\n",
        "k_clusters = 3\n",
        "\n",
        "k_means = KMeans(n_clusters=k_clusters, n_init=10)\n",
        "cluster_label = k_means.fit_predict(X_red)\n",
        "\n",
        "# 3d\n",
        "fig = plt.figure(figsize=(16, 4))\n",
        "ax = fig.add_subplot(131, projection='3d', elev=30, azim=160)\n",
        "ax.scatter(X[:, 0], X[:, 1], X[:, 2], c=cluster_label)\n",
        "ax.set_xlabel(r'$x_0$')\n",
        "ax.set_ylabel(r'$x_1$')\n",
        "ax.set_zlabel(r'$x_2$')\n",
        "# 2d PC\n",
        "ax = fig.add_subplot(132)\n",
        "ax.scatter(X_red[:, 0], X_red[:, 1], c=cluster_label)\n",
        "ax.set_xlabel(r'$x_0$')\n",
        "ax.set_ylabel(r'$x_1$')\n",
        "ax.axis(\"equal\")\n",
        "ax.set_title(\"clusters\")\n",
        "\n",
        "# classes\n",
        "ax = fig.add_subplot(133)\n",
        "ax.scatter(X_red[:, 0], X_red[:, 1], c=iris.target)\n",
        "ax.set_xlabel(r'$x_0$')\n",
        "ax.set_ylabel(r'$x_1$')\n",
        "ax.axis(\"equal\")\n",
        "ax.set_title(\"classes\")\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Overall not a bad result considering the two classes are quite close to one another. Don't let the difference in color fool you, the encoding of the cluster might be different from the encoding of the class. The important thing is the separation."
      ],
      "metadata": {
        "id": "8uEIbWY8FqzN"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GGlmm-BfwRPI"
      },
      "source": [
        "#### Final considerations\n",
        "\n",
        "- We can cross-validate the number of clusters ([silhouette](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.silhouette_score.html))\n",
        "- Variety of clustering methods with different behaviours ([comparison](https://scikit-learn.org/stable/modules/clustering.html#clustering))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RTWiyb1b9-Mt"
      },
      "source": [
        "## 7.2 Image compression with Fashion-MNIST\n",
        "\n",
        "---\n",
        "\n",
        "In this part, we will see how we can compress an image dataset, reducing the number of components needed to represent each image. For this purpose we consider the dataset Fashion-MNIST provided by Zalando."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))])\n",
        "\n",
        "fashion_mnist = torchvision.datasets.FashionMNIST('./data', train=False, transform=transform, download=True)\n",
        "\n",
        "classes = ('T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
        "        'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle Boot')\n",
        "\n",
        "print('Dataset has {} instances'.format(len(fashion_mnist)))\n",
        "print(f'Shape of images: {fashion_mnist.data.shape[1:]}')\n",
        "\n",
        "X = fashion_mnist.data.numpy()\n",
        "y = fashion_mnist.targets.numpy()"
      ],
      "metadata": {
        "id": "TmDwxarEGljd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's plot some samples to get a general idea of the dataset\n",
        "np.random.seed(42)\n",
        "\n",
        "plt.figure(figsize=(10,10))\n",
        "for i in range(25):\n",
        "    plt.subplot(5,5,i+1)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.grid(False)\n",
        "    plt.imshow(X[i].reshape(28, 28), cmap=\"binary\")\n",
        "    plt.xlabel(classes[y[i]])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "uWZp_g9HNJ15"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dfH5vrGYNZWo"
      },
      "source": [
        "Vectorize the images."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l0gdkrdK-PX0"
      },
      "outputs": [],
      "source": [
        "n_samples = X.shape[0]\n",
        "X, y = X[:n_samples], y[:n_samples]\n",
        "print(\"X shape:\", X.shape)\n",
        "\n",
        "# Reshape to vectors and rescale to [0, 1]\n",
        "w, h = X.shape[1:3]\n",
        "X_vec = X.reshape(-1, w * h) /255.\n",
        "print(\"X_vec:\", X_vec.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nNbUIuyFdF5h"
      },
      "source": [
        "Let's plot the principal components."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pJHcd8K9-a2Z"
      },
      "outputs": [],
      "source": [
        "# PCA\n",
        "n_components = 200\n",
        "\n",
        "X_mean = X_vec.mean(axis=0, keepdims=True)\n",
        "X0 = X_vec - X_mean\n",
        "pca = PCA(n_components=n_components)\n",
        "pca.fit(X0)\n",
        "\n",
        "plt.figure()\n",
        "plt.title('eigenvalues')\n",
        "plt.plot(pca.singular_values_**2)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YVAEH-x8Hyy7"
      },
      "outputs": [],
      "source": [
        "# compress\n",
        "X_red = pca.transform(X0)\n",
        "# extract\n",
        "X_rec = pca.inverse_transform(X_red)\n",
        "X_rec += X_mean\n",
        "\n",
        "# reshape to image size and range\n",
        "x_image_rec = 255 * X_rec.clip(0, 1).reshape(-1, w, h)\n",
        "x_image_orig = 255 * X.clip(0, 1).reshape(-1, w, h)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# draw some random images\n",
        "p = np.random.choice(X.shape[0], size=5)\n",
        "\n",
        "plt.figure(figsize=(7,10))\n",
        "for i in range(0,len(p)*2 -1,2):\n",
        "    plt.subplot(len(p),2,i+1)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.grid(False)\n",
        "    plt.title(\"Original\")\n",
        "    plt.imshow(X[p[i//2]].reshape(28, 28), cmap=\"binary\")\n",
        "    plt.subplot(len(p),2,i+2)\n",
        "    plt.title(\"Reconstruction\")\n",
        "    plt.imshow(x_image_rec[p[i//2]].reshape(28, 28), cmap=\"binary\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "_BiWnBXWJosV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lr-KjJWldjEj"
      },
      "source": [
        "It seems that we are able to decently rebuild the original images using way less features! The object seem still to be recognizable. Now what happens if we add noise to the original images?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "47By6mUp47MO"
      },
      "source": [
        "### Image denoising"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zoioU09-_0lz"
      },
      "outputs": [],
      "source": [
        "# Add noise to X\n",
        "X_noisy = X_vec + np.random.randn(*X_vec.shape)*.15\n",
        "\n",
        "# PCA\n",
        "n_components = 75 # let's use even less principal components this time\n",
        "X_mean = X_noisy.mean(axis=0, keepdims=True)\n",
        "X0 = X_noisy - X_mean\n",
        "pca = PCA(n_components=n_components)\n",
        "pca.fit(X0)\n",
        "\n",
        "plt.figure()\n",
        "plt.title('eigenvalues')\n",
        "plt.plot(pca.singular_values_**2)\n",
        "plt.show()\n",
        "\n",
        "# compress\n",
        "X_red = pca.transform(X0)\n",
        "# extract\n",
        "X_rec = pca.inverse_transform(X_red)\n",
        "X_rec += X_mean\n",
        "\n",
        "# reshape to image size and range\n",
        "x_image_orig = 255 * X.clip(0, 1).reshape(-1, w, h)\n",
        "x_image_noisy = 255 * X_noisy.clip(0, 1).reshape(-1, w, h)\n",
        "x_image_rec = 255 * X_rec.clip(0, 1).reshape(-1, w, h)\n",
        "\n",
        "# draw some random images\n",
        "np.random.seed(42)\n",
        "p = np.random.choice(X.shape[0], size=5)\n",
        "\n",
        "plt.figure(figsize=(7,10))\n",
        "for i in range(0,len(p)*3 -1,3):\n",
        "    plt.subplot(len(p),3,i+1)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.grid(False)\n",
        "    plt.title(\"Original\")\n",
        "    plt.imshow(X[p[i//3]].reshape(28, 28), cmap=\"binary\")\n",
        "    plt.subplot(len(p),3,i+2)\n",
        "    plt.title(\"Noisy\")\n",
        "    plt.imshow(x_image_noisy[p[i//3]].reshape(28, 28), cmap=\"binary\")\n",
        "    plt.subplot(len(p),3,i+3)\n",
        "    plt.title(\"Reconstruction\")\n",
        "    plt.imshow(x_image_rec[p[i//3]].reshape(28, 28), cmap=\"binary\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Notice that the noise introduced is mostly gone and only useful features are preserved."
      ],
      "metadata": {
        "id": "f8Jojg9CT3mM"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RkOfev2beS23"
      },
      "source": [
        "Now let's see if using only two dimensions we are able to plot the dataset in a clusterized fashion."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FgKekvc7QYD_"
      },
      "outputs": [],
      "source": [
        "x_dim, y_dim = 0, 1 # we use the first two components of PCA\n",
        "plt.figure(figsize=(16, 12))\n",
        "for d in range(10):\n",
        "    ii = np.where(y==d)[0]\n",
        "    plt.scatter(X_red[ii][:, x_dim], X_red[ii][:, y_dim], marker=f\"${d}$\", label=d)\n",
        "plt.xlabel(\"$pc_0$\",fontsize=12)\n",
        "plt.ylabel(\"$pc_1$\",fontsize=12)\n",
        "plt.legend(labels=classes)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Not bad, overall we can see that even with only two features there's some separation between classes.\n",
        "\n",
        "__Advanced note:__ Several other methods are commonly used in combination with PCA to obtain visualization of high dimensional datasets. A commonly used one is [TSNE](https://scikit-learn.org/stable/modules/generated/sklearn.manifold.TSNE.html), also implemented in sklearn. The following snippet of code is an example of how it's used (it can take up to 5 minutes to run it)."
      ],
      "metadata": {
        "id": "TbloPgvdUZ2X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.manifold import TSNE\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import matplotlib as mpl\n",
        "\n",
        "\n",
        "def plot_digits(X, y, min_distance=0.05, figsize=(13, 10)):\n",
        "    \"\"\"Just a helper function for the visualization, no need to understand it\"\"\"\n",
        "    X_normalized = MinMaxScaler().fit_transform(X)\n",
        "    neighbors = np.array([[10., 10.]])\n",
        "    plt.figure(figsize=figsize)\n",
        "    cmap = mpl.cm.get_cmap(\"prism\")\n",
        "    digits = np.unique(y)\n",
        "    for digit in digits:\n",
        "        plt.scatter(X_normalized[y == digit, 0], X_normalized[y == digit, 1], c=[cmap(digit / 9)])\n",
        "    plt.axis(\"off\")\n",
        "    ax = plt.gcf().gca()  # get current axes in current figure\n",
        "    for index, image_coord in enumerate(X_normalized):\n",
        "        closest_distance = np.linalg.norm(np.array(neighbors) - image_coord, axis=1).min()\n",
        "        if closest_distance > min_distance:\n",
        "            neighbors = np.r_[neighbors, [image_coord]]\n",
        "            plt.text(image_coord[0], image_coord[1], str(int(y[index])),\n",
        "                         color=cmap(y[index] / 9), fontdict={\"weight\": \"bold\", \"size\": 16})\n",
        "\n",
        "pca_tsne = Pipeline([\n",
        "    (\"pca\", PCA(n_components=0.9, random_state=42)),\n",
        "    (\"tsne\", TSNE(n_components=2, random_state=42)),\n",
        "])\n",
        "X_pca_tsne_reduced = pca_tsne.fit_transform(X0)\n",
        "plot_digits(X_pca_tsne_reduced, y)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "ZCIiXfFdOtRB"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
